{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "sys.path.append('..')\n",
    "from load_data import load_data\n",
    "from config import xvertseg_dir, verse2019_dir, resolution, patch_size, batch_size\n",
    "from tiger.patches import PatchExtractor3D\n",
    "import torch\n",
    "from monai.transforms import Compose, RandGaussianNoise, RandRotate, RandGaussianSmooth, RandGaussianSharpen, Rand3DElastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from corresponding data dir\n",
    "xvertseg_imgs, xvertseg_msks, xvertseg_scores = load_data(xvertseg_dir, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for a simple dataset containing patches of vertebra and associated scores.\n",
    "    Also keeps track of where the vertebra was found in the dataset (ID and type)'\n",
    "    \"\"\"\n",
    "    def __init__(self, scores, images, masks, patch_size, transforms=False):\n",
    "        self.patches = []                      # (N, 2)    N is the number of vertebrae, img and msk channel\n",
    "        self.scores = []                       # (N, 1)    fractured or not\n",
    "        self.sources = []                      # (N, 1)    dataset of where the image was found\n",
    "        self.IDS = []                          # (N, 1)    ID of the image, in which this vertebra is found\n",
    "        self.vertebrae = []                    # (N, 1)    8-25: T1-T12, L1-L6\n",
    "\n",
    "        # transform after patch extraction\n",
    "        if transforms:\n",
    "            self.spatial_transforms = Compose([\n",
    "                RandRotate(range_x= 1/6 *np.pi, range_y=1/6 *np.pi, range_z=0, prob=0.5, mode='nearest')                \n",
    "            ])\n",
    "            \n",
    "            self.other_transforms = Compose([\n",
    "                RandGaussianNoise(prob=0.2),\n",
    "                RandGaussianSharpen(prob=0.2),\n",
    "                RandGaussianSmooth(prob=0.2)\n",
    "            ])\n",
    "\n",
    "        # the patch extraction\n",
    "        for row, mask in enumerate(masks):\n",
    "            # get the dataset and id of this case\n",
    "            source = scores[row][0]\n",
    "            id = scores[row][1]\n",
    "\n",
    "            # get the vert scores, 18 vertebrae, grade and case, need float to detect nans\n",
    "            vert_scores = scores[row][2:].reshape(18, 2).astype(float)\n",
    "\n",
    "            # find annotated labels in the score sheet\n",
    "            for i, vert_score in enumerate(vert_scores):\n",
    "                if not (np.isnan(vert_score).any()):\n",
    "                    label = i + 8                              # because we skip the 7 C-vertebrae\n",
    "\n",
    "                    # if we also find this label in the mask\n",
    "                    if label in np.unique(mask):\n",
    "                        # get the patch containing this vertebra\n",
    "                        centre = tuple(np.mean(np.argwhere(mask == label), axis=0, dtype=int))\n",
    "\n",
    "                        # patch extractor for the image, pad with -1000 (air)\n",
    "                        patch_extracter_img = PatchExtractor3D(images[row], pad_value=-1000)\n",
    "                        patch_img = patch_extracter_img.extract_cuboid(centre, patch_size)\n",
    "\n",
    "                        # patch extractor for the mask\n",
    "                        patch_extracter_msk = PatchExtractor3D(mask)\n",
    "                        patch_msk = patch_extracter_msk.extract_cuboid(centre, patch_size)\n",
    "                        patch_msk = np.where(patch_msk == label, 1, 0)  # only contain this vertebra, binary\n",
    "\n",
    "                        # add channel dimension\n",
    "                        patch_img = np.expand_dims(patch_img, axis=0)\n",
    "                        patch_msk = np.expand_dims(patch_msk, axis=0)\n",
    "                        patch = np.concatenate((patch_img, patch_msk))\n",
    "\n",
    "                        # add score and info about this patch\n",
    "                        self.patches.append(patch)\n",
    "                        self.scores.append(vert_score.any().astype(int))       # binarize: fractured or not\n",
    "                        self.sources.append(source)\n",
    "                        self.IDS.append(id)\n",
    "                        self.vertebrae.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns N, the number of vertebrae in this dataset.\n",
    "        \"\"\"\n",
    "        return len(self.patches)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"\"\n",
    "        Return a single sample: a patch of mask containing one vertebra and its binary score\"\n",
    "        \"\"\"\n",
    "        # use float32 as type\n",
    "        x = torch.tensor(self.patches[i], dtype=torch.float32)\n",
    "        y = torch.tensor(self.scores[i], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        # apply transformation, only for the training set\n",
    "        if self.spatial_transforms:\n",
    "            # apply spatial transform on both image and mask\n",
    "            x_trans = self.spatial_transforms(x)\n",
    "            \n",
    "            # apply the others only on the image\n",
    "            x_trans[0] = self.other_transforms(x_trans[0])\n",
    "            return x, x_trans, y\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataset\n",
    "np_scores = xvertseg_scores.to_numpy()\n",
    "dataset = Dataset(np_scores[:1], xvertseg_imgs[:1], xvertseg_msks[:1], patch_size, transforms=True)\n",
    "loader = DataLoader(dataset, batch_size=8, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, x_trans, y = next(iter(loader))\n",
    "    \n",
    "num_samples = x.shape[0]\n",
    "\n",
    "for s in range(num_samples):    \n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "\n",
    "    x_img = x[s, 0, :, :]\n",
    "    x_msk = x[s, 1, :, :]\n",
    "    x_trans_img = x_trans[s, 0, :, :]\n",
    "    x_trans_msk = x_trans[s, 1, :, :]\n",
    "    label = y[s]\n",
    "\n",
    "    mid_slice = x_img.shape[0] // 2\n",
    "    x_msk = np.ma.masked_where(x_msk == 0, x_msk)  \n",
    "    x_trans_msk = np.ma.masked_where(x_trans_msk == 0, x_trans_msk)  \n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(x_img[mid_slice, :, :], cmap='gray')\n",
    "    plt.imshow(x_msk[mid_slice, :, :], alpha=0.2)\n",
    "    plt.title('Before transforms')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(x_trans_img[mid_slice, :, :], cmap='gray')\n",
    "    plt.imshow(x_trans_msk[mid_slice, :, :], alpha=0.2)\n",
    "    plt.title('After transforms')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
